{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2e387b2",
   "metadata": {},
   "source": [
    "# Intro to Decision Trees\n",
    "_Authors_: Maitiu Sexton, David Yerrington, Matt Brems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7519f",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "\n",
    "- Explain how a decision tree functions\n",
    "- Calculate and understand Gini impurity\n",
    "- Build a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3ea186",
   "metadata": {},
   "source": [
    "## How does a decision tree function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e8a7aa",
   "metadata": {},
   "source": [
    "1. Take a dataset with features $X$ and target $Y$\n",
    "2. Find rules based on $X$ to best split the data at each **internal node** (colored yellow)\n",
    "3. Sort the data such that each **leaf node** (colored green) is as \"pure\" as possible\n",
    "\n",
    "Typically, decision trees are represented with graphs like this very simple one.\n",
    "\n",
    "<img src=\"./decision_tree_example.png\" width=\"750\"/>\n",
    "\n",
    "(This image was created using [Draw.io](https://www.draw.io/))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3cc7d",
   "metadata": {},
   "source": [
    "## But how do we choose which split(s) to make?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da12b0a1",
   "metadata": {},
   "source": [
    "If we were to:\n",
    "- Randomly select a datapoint in our node, then\n",
    "- Randomly assign it a label (classify it) according to the distribution of classes in that node\n",
    "\n",
    "Then what's the probability that we're wrong? \\\n",
    "That's **Gini Impurity**. You can think of it as a measure of homogeneity, or how mixed a dataset is. \\\n",
    "It is calculated as follows, similarly to Mean Squared Error:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d186c22f",
   "metadata": {},
   "source": [
    "### Gini Impurity Calulation\n",
    "Suppose $p_i$ is the probability that class $i$ would be chosen uniformly at random out of $n$ total classes. Then:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\text{Gini impurity} &=& \\sum_{i=1}^{n} p_i(1 - p_i) \\\\\n",
    "                     &=& 1 - \\sum_{i=1}^{n} p_i^2 \\\\\n",
    "\\text{Gini impurity (2 classes)} &=& 1 - p_1^2 - p_2^2 \\\\\n",
    "\\text{Gini impurity (3 classes)} &=& 1 - p_1^2 - p_2^2 - p_3^2 \\\\\n",
    "\\end{eqnarray*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be5ad78",
   "metadata": {},
   "source": [
    "<details><summary>(click here for info on Gini impurity score ranges)</summary>\n",
    "    \n",
    "- In the case of **binary** classification, a perfectly homogeneous set will have a gini score of 0, whereas a completely random set will have a gini score of 0.5 (because you have a 50/50 chance of being right or wrong)\n",
    "    \n",
    "- For 3 classes, Gini impurity ranges from 0 to 0.6667\n",
    "    \n",
    "- If we have $k$ classes, Gini impurity ranges from 0 to $1-\\frac{1}{k}$\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c57ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To better understand, let's see it in action\n",
    "def gini(obs):\n",
    "    \n",
    "    gini_probs = list()\n",
    "    \n",
    "    for p_i in set(obs): # using set because we only want to look at each class once\n",
    "        p = (obs.count(p_i) / len(obs))\n",
    "        gini_probs.append(p ** 2)\n",
    "        \n",
    "    impurity = 1 - sum(gini_probs)\n",
    "    \n",
    "    return impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a819dc44",
   "metadata": {},
   "source": [
    "### Check for Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab5ae22",
   "metadata": {},
   "source": [
    "1. Write an example of a list that has a Gini score of 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca23f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = ['yes', 'yes', 'yes', 'yes']\n",
    "\n",
    "gini(list_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256ba344",
   "metadata": {},
   "source": [
    "2. Write an example of a list that has a Gini score of 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3857ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_2 = ['yes', 'yes', 'no', 'no']\n",
    "\n",
    "gini(list_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3245eb9",
   "metadata": {},
   "source": [
    "3. What gini score do you expect the following list to have? (Try not to run the function before thinking about the question):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc4f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d06797",
   "metadata": {},
   "source": [
    "4. _(bonus)_: Can you think of another list with the same set of elements and the same Gini score as `list_3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1ff076",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6219df4",
   "metadata": {},
   "source": [
    "### A decision tree chooses each split by running through all the possible splits and choosing the one with the lowest Gini score\n",
    "- if the Gini score of the next node is going to be higher, it stops and creates a leaf node\n",
    "- this is a **greedy** algorithm with a tendency to overfit, so we can employ early stopping and regularization (tomorrow's lesson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e714953",
   "metadata": {},
   "source": [
    "## Let's build a decision tree of our own using the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5010932a",
   "metadata": {},
   "source": [
    "|target|species   |\n",
    "|:-----|:---------|\n",
    "|0     |setosa    |\n",
    "|1     |versicolor|\n",
    "|2     |virginica |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d236fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data = iris['data'], columns = iris['feature_names'])\n",
    "df['species'] = iris['target']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ede0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, Test, Split (use random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c89b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with random_state = 123\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0a667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad035f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4d8998",
   "metadata": {},
   "source": [
    "## This is how our model was actually trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d005e31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (50, 30))\n",
    "\n",
    "# Plot our tree.\n",
    "plot_tree(dt,\n",
    "          feature_names = X_train.columns,\n",
    "          class_names = ['setosa', 'versicolor', 'virginica'],\n",
    "          filled = True);\n",
    "# True values go left, False go right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69623a6b",
   "metadata": {},
   "source": [
    "## Concluding Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09af7f2b",
   "metadata": {},
   "source": [
    "### Pros\n",
    "- nonparametric; no assumptions are made about how our data or errors are distributed\n",
    "- no need to scale our data\n",
    "- easy to interpret (supervised)\n",
    "- fits very quickly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822a0968",
   "metadata": {},
   "source": [
    "### Cons\n",
    "- greedy algorithm\n",
    "    - can very easily overfit\n",
    "- algorithm is locally optimal\n",
    "    - could miss patterns as you go down the tree due to already splitting out certain subset of data\n",
    "- don't work well with unbalanced data\n",
    "    - bias goes towards the majority class (the flip side of our first pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fbace9",
   "metadata": {},
   "source": [
    "## For Further Consideration\n",
    "What is an example of a situation in which you feel a decision tree would be useful?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
